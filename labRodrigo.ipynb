{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.4\n",
      "c:\\Users\\admin\\Desktop\\Laboratorios\\.conda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylidc as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from radiomics import featureextractor\n",
    "print(np.__version__)\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "#print(pl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para lembrar apenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui elimina os pacientes que nao tem anotações (TÊM DE CORRER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\manifest-1600709154662\\\\LIDC-IDRI\"\n",
    "\n",
    "# List with all the eliminated patients - the one who were not evaluated\n",
    "deleted_patients = []\n",
    "# Ordered list of all the subfolders\n",
    "patient_folders = sorted(os.listdir(input_directory))\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    patient_folder_path = os.path.join(input_directory, patient_folder)\n",
    "\n",
    "    # Id of the patient - 'LIDC-IDRI-xxxx'\n",
    "    patient_id = os.path.basename(patient_folder_path)\n",
    "    \n",
    "    patient_scans = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id)\n",
    "    \n",
    "    for scan in patient_scans:\n",
    "        anns = scan.annotations\n",
    "        \n",
    "        if not anns:\n",
    "            # Path to the folder we want to eliminate\n",
    "            delete_folder = os.path.join(input_directory, patient_id) \n",
    "\n",
    "            # Verify if the folder exists\n",
    "            if os.path.exists(delete_folder):\n",
    "                # Verify if it is a folder\n",
    "                if os.path.isdir(delete_folder):\n",
    "                    # Remove recursively\n",
    "                    shutil.rmtree(delete_folder)\n",
    "                    print(f\"The folder '{patient_id}' and its content were removed successfully\")\n",
    "                    deleted_patients.append(patient_id)\n",
    "                else:\n",
    "                    print(f\"'{patient_id}' is not a folder.\")\n",
    "            else:\n",
    "                print(f\"The folder '{patient_id}' does not exist in the expecified path.\")\n",
    "\n",
    "# If desired - save the list on a file  \n",
    "folder = \"deleted_patients.txt\"\n",
    "\n",
    "with open(folder, 'w') as arquivo:\n",
    "    # Saves the patients patient_id on a file named deleted_patients.txt\n",
    "    for element in deleted_patients:\n",
    "        arquivo.write(element + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos ficheiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodule_counts = pd.read_excel('lidc-idri-nodule-counts-6-23-2015.xlsx', engine='openpyxl')\n",
    "patient_diagnoses = pd.read_excel('tcia-diagnosis-data-2012-04-20.xls')\n",
    "dicom_metadata = pd.read_csv('LIDC-IDRI_MetaData.csv')\n",
    "\n",
    "\n",
    "# Inicializar pylidc para trabalhar com as anotações XML\n",
    "cases = pl.query(pl.Scan).all()\n",
    "\n",
    "\n",
    "\n",
    "print(nodule_counts.head())\n",
    "print(100*\"*\")\n",
    "print(patient_diagnoses.head())\n",
    "print(100*\"*\")\n",
    "print(dicom_metadata.head())\n",
    "print(100*\"*\")\n",
    "print(len(cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomear colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear as colunas para 'PatientID' se necessário\n",
    "nodule_counts.rename(columns={'TCIA Patent ID': 'PatientID'}, inplace=True)\n",
    "patient_diagnoses.rename(columns={'TCIA Patient ID': 'PatientID'}, inplace=True)\n",
    "dicom_metadata.rename(columns={'Subject ID': 'PatientID'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dos datasets Nodule_counts , dicom_metadata , anotações (XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info = pd.merge( dicom_metadata,nodule_counts, on='PatientID', how='inner')\n",
    "print(patient_info)\n",
    "\n",
    "\n",
    "\n",
    "# Unificar com os metadados DICOM\n",
    "complete_data = pd.merge(patient_info, patient_diagnoses, on='PatientID', how='inner')\n",
    "\n",
    "print(complete_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do dataset com as anotações de cada nodulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "np.int = np.int32  # Garantir compatibilidade com versões mais novas do NumPy\n",
    "\n",
    "# Criar uma lista para armazenar informações detalhadas dos contornos dos nódulos\n",
    "nodule_data = []\n",
    "\n",
    "# Iterar sobre todos os casos/pacientes\n",
    "scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == 'LIDC-IDRI-0001').first()\n",
    "\n",
    "patient_id = scan.patient_id\n",
    "print(f\"Processing Patient ID: {patient_id}\")\n",
    "\n",
    "# Iterar sobre os nódulos do paciente\n",
    "# Iterar sobre os nódulos do paciente\n",
    "for nodule_list in scan.cluster_annotations():\n",
    "    if len(nodule_list) > 0:\n",
    "        for nodule in nodule_list:\n",
    "            print(f\"Inspecting Nódulo {nodule.id}: {nodule}\")\n",
    "            \n",
    "            # Armazenar o ID do contorno e a posição da fatia axial (Z_Position)\n",
    "            nodule_data.append({\n",
    "                'PatientID': patient_id,\n",
    "                'NoduleID': nodule.id,\n",
    "                'InternalStructure': nodule.internalStructure,\n",
    "                'Sphericity': nodule.sphericity,\n",
    "                'Calcification': nodule.calcification,\n",
    "                'Subtlety': nodule.subtlety,\n",
    "                'Lobulation': nodule.lobulation,\n",
    "                'Margin': nodule.margin,\n",
    "                'Spiculation': nodule.spiculation,\n",
    "                'Texture': nodule.texture,\n",
    "                'Malignancy': nodule.malignancy\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Nódulo {nodule_list} está vazio.\")\n",
    "\n",
    "# Converter para DataFrame\n",
    "nodule_df = pd.DataFrame(nodule_data)\n",
    "\n",
    "nodule_df.to_csv('C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\noduledf2.csv', index=False)\n",
    "\n",
    "# Exibir o DataFrame\n",
    "print(nodule_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformas os dois datasets em csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodule_df.to_csv('C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\nodule_df.csv', index=False)\n",
    "#complete_data.to_csv('C:\\\\Users\\\\gjoli\\\\Desktop\\\\UNI3\\\\lab\\\\complete_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHSDSAHDUASHDUAHSD NORMALIZAÇÂO (Nao esta a funcionar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(volume, intercept, slope):\n",
    "    \"\"\" Normaliza o volume de acordo com os valores de intercept e slope fornecidos pelo DICOM \"\"\"\n",
    "    volume = volume.astype(np.float32)\n",
    "    volume = volume * slope + intercept\n",
    "    # Limitar os valores em uma faixa significativa, como -1000 a 400, que é típico para pulmões\n",
    "    volume = np.clip(volume, -1000, 400)\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui começa a cena de sacar as coordenadas e isolar os nodulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodule_coordinates(scan, patient_id): \n",
    "    # Garantir que np.int e np.bool estejam definidos corretamente\n",
    "    np.int = np.int32\n",
    "    np.bool = np.bool_\n",
    "\n",
    "    # Verificar se o scan está vazio\n",
    "    if scan is None:\n",
    "        print(f\"Nenhum scan encontrado para o paciente {patient_id}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Obter as anotações dos nódulos\n",
    "    nodules = scan.cluster_annotations()\n",
    "    \n",
    "    # Verificar se há nódulos no scan\n",
    "    if len(nodules) == 0:\n",
    "        print(f\"Nenhum nódulo encontrado para o paciente {patient_id}\")\n",
    "        return None, None, None\n",
    "    '''\n",
    "    # Extrair intercept e slope da primeira fatia DICOM\n",
    "    try:\n",
    "        dicom_slice = scan.load_all_dicom_images()[0]  # Carrega a primeira fatia\n",
    "        intercept = dicom_slice.RescaleIntercept\n",
    "        slope = dicom_slice.RescaleSlope\n",
    "    except AttributeError:\n",
    "        print(\"Não foi possível obter intercept e slope das fatias DICOM\")\n",
    "        return None, None, None\n",
    "    '''\n",
    "    vec_masks = []\n",
    "    vol = scan.to_volume()  # Inicializar o volume fora do loop\n",
    "\n",
    "    # Verificar se o volume foi corretamente carregado\n",
    "    if vol is None:\n",
    "        print(f\"Erro ao carregar o volume para o paciente {patient_id}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Normalizar o volume\n",
    "    # vol = normalize(vol, intercept, slope)\n",
    "\n",
    "    # Percorrer cada nódulo anotado\n",
    "    for annotation in nodules:\n",
    "        # Inicializar uma máscara vazia com o mesmo shape do volume\n",
    "        consensus_mask_full = np.zeros_like(vol, dtype=bool)\n",
    "\n",
    "        # Percorrer os contornos do nódulo\n",
    "        for contour in annotation:\n",
    "            # Obter as coordenadas da caixa delimitadora (slices) para o contorno\n",
    "            slices = contour.bbox()\n",
    "\n",
    "            # Criar a máscara do contorno\n",
    "            mask = contour.boolean_mask()\n",
    "\n",
    "            if consensus_mask_full[slices].shape == mask.shape:\n",
    "                consensus_mask_full[slices] |= mask  # Combine as máscaras se os shapes forem iguais\n",
    "            else:\n",
    "                print(f\"Shapes incompatíveis: {consensus_mask_full[slices].shape} e {mask.shape}\")\n",
    "\n",
    "            # Inserir a máscara da anotação na posição correta dentro da máscara completa\n",
    "            #consensus_mask_full[slices] |= mask  # Combinar as máscaras usando OR lógico\n",
    "\n",
    "        vec_masks.append(consensus_mask_full)\n",
    "\n",
    "    # Retornar as máscaras, o volume e o ID do último contorno processado\n",
    "    return vec_masks, vol, contour.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import draw\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def isolate_nodule_with_coordinates(consensus_mask_full,vol):\n",
    "    \n",
    "    # Encontrar a fatia com a maior área do nódulo\n",
    "    slice_areas = consensus_mask_full.sum(axis=(0, 1))\n",
    "    max_slice_idx = np.argmax(slice_areas)\n",
    "\n",
    "    # Obter a imagem e a máscara da fatia correspondente\n",
    "    img_slice = vol[:, :, max_slice_idx]\n",
    "    mask_slice = consensus_mask_full[:, :, max_slice_idx]\n",
    "\n",
    "    return img_slice,mask_slice, max_slice_idx\n",
    "\n",
    "\n",
    "'''\n",
    "# Exemplo de uso da função\n",
    "# Vamos supor que 'pixel_array' é a imagem e 'coordinates' são as coordenadas fornecidas\n",
    "\n",
    "# Aqui 'pixel_array' seria a tua imagem DICOM carregada\n",
    "# coordinates seria o array de coordenadas que mencionaste\n",
    "isolated_nodule = isolate_nodule_with_coordinates(pixel_array, coordinates)\n",
    "\n",
    "# Visualizar o nódulo isolado\n",
    "plt.imshow(isolated_nodule, cmap='gray')\n",
    "plt.title(\"Nódulo Isolado\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def normalize_image(image, target_shape=(512, 512)):\n",
    "    \"\"\"\n",
    "    Normaliza uma imagem para uma forma padrão, ajustando a escala e a dimensão.\n",
    "\n",
    "    Parameters:\n",
    "    - image: ndarray\n",
    "        A imagem original a ser normalizada.\n",
    "    - target_shape: tuple\n",
    "        A forma desejada da imagem normalizada (default é (512, 512)).\n",
    "\n",
    "    Returns:\n",
    "    - normalized_image: ndarray\n",
    "        A imagem normalizada.\n",
    "    \"\"\"\n",
    "    # Verifica se a imagem precisa de redimensionamento\n",
    "    if image.shape[:2] != target_shape:\n",
    "        # Usar a função resize da skimage para redimensionar corretamente\n",
    "        normalized_image = resize(image, target_shape, preserve_range=True)\n",
    "    else:\n",
    "        normalized_image = image\n",
    "    \n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui em baixo são as duas funções de guardar as máscaras. A segunda guarda a máscara em binário a primeira guarda em DICOM acho eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(image, patient_id, nodule_id, sop_instance_uid, base_masks_dir):\n",
    "    # Criar o diretório com base no PatientID e NoduleID\n",
    "    save_dir = os.path.join(base_masks_dir, str(patient_id), str(nodule_id))\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Cria as pastas se não existirem\n",
    "    \n",
    "    # Salvar a imagem no formato .npy\n",
    "    file_path = os.path.join(save_dir, f'{sop_instance_uid}.npy')  # Nome do arquivo com SOPInstanceUID\n",
    "    np.save(file_path, image)\n",
    "    \n",
    "    print(f'Salvo: {file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para fazer as mascaras. Se quiserem imprimir as imagens tirem o hastag dos plts e assim. Se quiserem guardar as mascaras tirem o hastag do save mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_nodules(base_masks_dir):\n",
    "    # Verificar se o ID do paciente é menor ou igual a 57\n",
    "    for i in range(1, 55):  # De 1 até 55 (incluindo)\n",
    "        patient_id = f\"LIDC-IDRI-{i:04d}\"  # Formato do ID com zeros à esquerda\n",
    "\n",
    "        print(patient_id)\n",
    "\n",
    "        if patient_id ==\"LIDC-IDRI-0028\" or patient_id ==\"LIDC-IDRI-0032\":\n",
    "            continue\n",
    "\n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id).first()\n",
    "\n",
    "        #patient_dir = os.path.join(base_dir, patient_id)\n",
    "\n",
    "        dicom_files = scan.load_all_dicom_images()\n",
    "\n",
    "        #print(patient_dir)\n",
    "\n",
    "        # Obter as coordenadas do nódulo\n",
    "        vec_masks, vol, nodule_id = get_nodule_coordinates(scan,patient_id)\n",
    "        \n",
    "        if vec_masks is None or vol is None:\n",
    "            print(f\"Nódulo ou volume não encontrado para {patient_id}.\")\n",
    "            continue\n",
    "        \n",
    "        #print(\"Comprimento: \", len(vec_masks))\n",
    "\n",
    "        for i in range (len(vec_masks)):\n",
    "\n",
    "            #print(\"Iteracao: \", i)\n",
    "\n",
    "            # Isolar o nódulo usando as coordenadas\n",
    "            img_slice, mask_slice, max_slice = isolate_nodule_with_coordinates(vec_masks[i], vol)\n",
    "\n",
    "            #print(max_slice)\n",
    "            #print(len(dicom_files))\n",
    "\n",
    "            #print(max_slice)\n",
    "\n",
    "            dicom_file_name = dicom_files[max_slice].SOPInstanceUID\n",
    "\n",
    "            #print(dicom_file_name)\n",
    "\n",
    "            # Criar uma figura com dois subplots\n",
    "            #fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "            # Exibir a imagem original\n",
    "            #axes[0].imshow(img_slice, cmap='gray')\n",
    "            #axes[0].contour(mask_slice, colors='r')\n",
    "            #axes[0].set_title('Original')\n",
    "            #axes[0].axis('off')\n",
    "\n",
    "            # Exibir a imagem com o contorno\n",
    "            #axes[1].imshow(mask_slice, cmap='gray')\n",
    "            #axes[1].set_title('Contorno')\n",
    "            #axes[1].axis('off')\n",
    "\n",
    "            # Mostrar a figura\n",
    "            #plt.show()\n",
    "\n",
    "            #save_mask(mask_slice, patient_id, nodule_id,dicom_file_name, base_masks_dir)\n",
    "\n",
    "# Usar a função\n",
    "base_dir = \"C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\manifest-1600709154662\\\\LIDC-IDRI\"\n",
    "base_masks_dir = \"C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\Masks\"\n",
    "isolate_nodules(base_masks_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir daqui começa o radiomics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from radiomics import featureextractor\n",
    "import pylidc as pl\n",
    "\n",
    "# Função para buscar o índice do arquivo DICOM correspondente pelo SOPInstanceUID\n",
    "def find_dicom_file(dicom_files, sop_instance_uid):\n",
    "    for i in range(len(dicom_files)):\n",
    "        dicom_file_name = dicom_files[i].SOPInstanceUID\n",
    "        if sop_instance_uid == dicom_file_name:\n",
    "            print(\"DICOM FILE NAME: \", dicom_file_name)\n",
    "            return i  # Retorna o índice do arquivo\n",
    "    return None\n",
    "\n",
    "# Caminho base para as máscaras\n",
    "base_mask_path = \"C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\Masks\"\n",
    "\n",
    "# Caminho do arquivo de parâmetros YAML\n",
    "params_file = \"C:\\\\Users\\\\admin\\\\Desktop\\\\Laboratorios\\\\Params.yaml\"\n",
    "\n",
    "# Inicializar o extrator de features\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(params_file)\n",
    "\n",
    "dic_list = []\n",
    "\n",
    "# Loop sobre as máscaras\n",
    "for root, dirs, files in os.walk(base_mask_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".npy\"):\n",
    "            mask_path = os.path.join(root, file)\n",
    "\n",
    "            # Extração das informações da máscara a partir do caminho\n",
    "            path_parts = mask_path.split(os.sep)\n",
    "            patient_id = path_parts[-3]  # PatientID\n",
    "            nodule_id = path_parts[-2]   # NoduleID\n",
    "            sop_instance_uid = file.replace(\".npy\", \"\")  # Usar o nome do arquivo npy como SOPInstanceUID\n",
    "\n",
    "            # Buscar o scan do paciente\n",
    "            scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id).first()\n",
    "\n",
    "            # Carregar todas as imagens DICOM do paciente\n",
    "            dicom_files = scan.load_all_dicom_images()\n",
    "\n",
    "            # Buscar o índice do arquivo DICOM correspondente usando o SOPInstanceUID\n",
    "            dicom_file_index = find_dicom_file(dicom_files, sop_instance_uid)\n",
    "\n",
    "            if dicom_file_index is not None:\n",
    "                # Obter o arquivo DICOM correspondente pelo índice\n",
    "                dicom_file = dicom_files[dicom_file_index]\n",
    "\n",
    "                # Ler a imagem DICOM\n",
    "                pixel_array = dicom_file.pixel_array\n",
    "\n",
    "                # Normalizar a imagem\n",
    "                pixel_array = normalize_image(pixel_array)\n",
    "\n",
    "                intercept = dicom_file.RescaleIntercept\n",
    "                slope = dicom_file.RescaleSlope\n",
    "\n",
    "                # Converter para Hounsfield Units\n",
    "                img_hu = pixel_array * slope + intercept\n",
    "\n",
    "                # Carregar a máscara npy\n",
    "                mask = np.load(mask_path)\n",
    "\n",
    "                # Converter a imagem e a máscara para SimpleITK\n",
    "                img_sitk = sitk.GetImageFromArray(img_hu.astype(np.float32))\n",
    "                mask_sitk = sitk.GetImageFromArray(mask.astype(np.uint8))\n",
    "\n",
    "                # Extrair as features usando o PyRadiomics\n",
    "                features = extractor.execute(img_sitk, mask_sitk, label=1)\n",
    "                dic_list.append(features)\n",
    "\n",
    "                # Adicionar PatientID e NoduleID às features\n",
    "                features['PatientID'] = patient_id\n",
    "                features['NoduleID'] = nodule_id\n",
    "\n",
    "            else:\n",
    "                print(f\"Arquivo DICOM correspondente para {mask_path} não encontrado.\")\n",
    "\n",
    "# Criar DataFrame a partir das features coletadas\n",
    "features_df = pd.DataFrame(dic_list)\n",
    "\n",
    "# Salvar as features extraídas em um arquivo CSV\n",
    "output_csv = f\"C:/Users/admin/Desktop/Laboratorios/Featurestodas/features_radiomics.csv\"\n",
    "features_df.to_csv(output_csv, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
